<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:itunes="http://www.itunes.com/dtds/podcast-1.0.dtd">
  <channel>
    <title>ArxivCaster</title>
    <link>https://example.com</link>
    <description>Daily summaries of arXiv papers with podcast audio.</description>
    <language>ja-jp</language>
    <generator>ArxivCaster</generator>
    <lastBuildDate>Thu, 28 Aug 2025 05:31:55 GMT</lastBuildDate>
    <itunes:explicit>false</itunes:explicit>
    <item>
      <title>Gaze into the Heart: A Multi-View Video Dataset for rPPG and Health
  Biomarkers Estimation</title>
      <link>https://yut0takagi.github.io/daily-use/viewer.html?slug=20250828-2508.17924v1</link>
      <guid isPermaLink="false">arxivcaster-20250828-2508.17924v1</guid>
      <pubDate>Thu, 28 Aug 2025 05:20:51 GMT</pubDate>
      <description># 論文要約: Gaze into the Heart: A Multi-View Video Dataset for rPPG and Health Biomarkers Estimation

## 背景
- リモート光脈波計測（rPPG）の進展は、公開データセットの課題に制約されている。
- 既存データセットは、サイズが小さい、プライバシーの懸念がある、条件の多様性が不足している。

## 課題
- 大規模かつ多様な条件下でのデータが不足しており、rPPGと健康バイオマーカーの推定に影響を及ぼしている。
- 既存のデータセットでは、異なる環境や状況でのデータ収集が不十分。

## 手法
- 3600件の同期ビデオ録画を600人の被験者から収集。
- さまざまな条件（安静時および運動後）で、複数の消費者向けカメラを使用して異なる角度から撮影。
- 各録画は、100 HzのPPG信号や心電図、動脈血圧、バイオマーカー、体温、酸素飽和度、呼吸率、ストレスレベルなどの健康指標とペアリング。

## 結果
- 提案したデータセットを用いて効率的なrPPGモデルを訓練。
- 既存のアプローチと比較し、クロスデータセットシナリオでのモデルの質を評価。

## 限界 / 今後の展望
- データセットのプライバシー管理や倫理的配慮が今後の課題。
- 多様な人種や年齢層を考慮したさらなるデータ収集が必要。
- 公開されたデータセットとモデルは、AI医療アシスタントの開発を加速する可能性があるが、実用化にはさらなる検証が求められる。</description>
      <enclosure url="https://yut0takagi.github.io/daily-use/episodes/20250828-2508.17924v1.mp3" type="audio/mpeg" />
    </item>
    <item>
      <title>CODA: Coordinating the Cerebrum and Cerebellum for a Dual-Brain Computer
  Use Agent with Decoupled Reinforcement Learning</title>
      <link>https://yut0takagi.github.io/daily-use/viewer.html?slug=20250828-2508.20096v1</link>
      <guid isPermaLink="false">arxivcaster-20250828-2508.20096v1</guid>
      <pubDate>Thu, 28 Aug 2025 05:31:55 GMT</pubDate>
      <description># CODA: 脳と小脳を連携させたデュアルブレインコンピュータエージェント

## 背景
- 自律エージェントは、科学計算などの専門的なドメインにおいて、長期的な計画と正確な実行の両方が求められる。
- 既存のアプローチは、計画が得意な一般的なエージェントと、実行が得意な専門的なエージェントとの間でトレードオフが存在する。

## 課題
- 従来の構成フレームワークは静的でトレーニングができず、経験からの適応が難しい。
- 科学的ドメインにおける高品質データの不足が、これらの制限をさらに悪化させている。

## 手法
- CODAは、一般的な計画者（Cerebrum）と専門的な実行者（Cerebellum）を統合した新しいトレーニング可能な構成フレームワーク。
- **ステージ1: 専門化**
  - 各科学アプリケーションに対して、少数のタスク軌跡から専門的な計画者をトレーニングするために、デカップルGRPOアプローチを適用。
- **ステージ2: 一般化**
  - 専門家から得られた成功した軌跡を集約し、最終的な計画者のための監視付きファインチューニングに使用。

## 結果
- ScienceBoardベンチマークの4つの挑戦的なアプリケーションで評価した結果、CODAはベースラインを大幅に上回り、オープンソースモデルの中で新たな最先端を確立。

## 限界 / 今後の展望
- CODAは特定の科学的アプリケーションに特化しているため、他のドメインへの適用可能性に関するさらなる研究が必要。
- 将来的には、より多様なタスクに対する汎用性を高めるための改良が求められる。</description>
      <enclosure url="https://yut0takagi.github.io/daily-use/episodes/20250828-2508.20096v1.mp3" type="audio/mpeg" />
    </item>
  </channel>
</rss>
